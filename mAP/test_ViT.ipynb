{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59894006-7e6c-4b3c-a582-962f412fa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abb8d50-e532-489f-b029-badcd7f24340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "image_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model.classifier = nn.Identity()\n",
    "model.eval()\n",
    "image = cv2.imread('./3.jpg')\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "print(model(**inputs).logits.flatten().detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2800bdbb-e840-4e9e-a433-e257f6a5b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "10000\n",
      "['64d323101c620faef16a9afd_6_agstore_vn.jpg\\n', '64da9bac1c3e4f08a26d57d8_2_chicland_vn.jpg\\n', '64d25998c0c243fd215f711f_0_hhluxury_vn.jpg\\n', '64da8ec21c3e4f08a26d43a6_1_chicland_vn.jpg\\n', '64d3238a1c620faef16a9beb_5_agstore_vn.jpg\\n']\n"
     ]
    }
   ],
   "source": [
    "query_path = 'query_images/'\n",
    "query_files = os.listdir(query_path)\n",
    "print(len(query_files))\n",
    "\n",
    "retrieval_path = 'images/'\n",
    "retrieval_files = os.listdir(retrieval_path)\n",
    "print(len(retrieval_files))\n",
    "\n",
    "print(query_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd17f296-f64c-49b4-a771-3cfed6a4e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:48<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 768)\n",
      "[[-0.27993301 -0.60705513 -0.13782115 ... -1.18001032 -0.33467326\n",
      "   0.1083511 ]\n",
      " [-1.7129395  -1.52261174 -1.22056258 ...  0.29758045 -0.26965815\n",
      "   0.39323455]\n",
      " [-2.15507483 -1.01523161 -0.9915843  ...  0.57583344 -0.82860291\n",
      "  -0.614016  ]\n",
      " ...\n",
      " [-0.54857415 -0.74036086 -0.56872332 ...  0.60176349 -1.03259015\n",
      "   0.24519567]\n",
      " [-0.65177894  0.1204956  -0.62647688 ...  0.58632255 -0.80400562\n",
      "   0.40110806]\n",
      " [-0.13847269 -2.023314   -0.02394438 ... -1.09086251  0.0556707\n",
      "  -1.26499426]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# n_queries = len(query_files)\n",
    "# query_matrix = np.zeros((n_queries, 768))\n",
    "# for i in tqdm(range(n_queries)):\n",
    "#     img = Image.open(query_path+query_files[i]).convert('RGB')\n",
    "#     inputs = image_processor(img, return_tensors=\"pt\")\n",
    "#     vector = model(**inputs).logits.flatten().detach().numpy()\n",
    "#     query_matrix[i, :] = vector    \n",
    "# np.save('ViT_query_matrix.npy', query_matrix)\n",
    "# print(query_matrix.shape)\n",
    "# print(query_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dc4f71-650e-4119-871e-f1dfae874bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████▊          | 7844/10000 [32:36<11:15,  3.19it/s]/home/binhng/anaconda3/envs/pt/lib/python3.11/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████| 10000/10000 [41:34<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.38280964,  0.32109451, -0.04591281, ..., -0.61909074,\n",
       "        -0.66329128,  0.11308269],\n",
       "       [-1.12061608, -0.67885423, -1.09242678, ..., -0.72129434,\n",
       "        -0.59230292,  0.79317075],\n",
       "       [ 0.11617942,  0.04850836,  1.36921823, ..., -0.29227048,\n",
       "         0.34549344,  0.92147171],\n",
       "       ...,\n",
       "       [ 0.67619127, -0.64255548,  0.77771777, ..., -1.92345464,\n",
       "         0.27126929,  0.96744001],\n",
       "       [-1.21616817, -0.27696335, -2.19197702, ..., -0.46903911,\n",
       "        -0.04838647,  0.89184904],\n",
       "       [-1.55875397, -0.23155649,  0.84143639, ...,  2.01766014,\n",
       "        -1.2676903 ,  1.10442913]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_retrievals = len(retrieval_files)\n",
    "# retrieval_matrix = np.zeros((n_retrievals, 768))\n",
    "# for i in tqdm(range(n_retrievals)):\n",
    "#     try:\n",
    "#         img = Image.open(retrieval_path+retrieval_files[i]).convert('RGB')\n",
    "#         inputs = image_processor(img, return_tensors=\"pt\")\n",
    "#         vector = model(**inputs).logits.flatten().detach().numpy()\n",
    "#         retrieval_matrix[i, :] = vector\n",
    "#     except:\n",
    "#         retrieval_matrix[i, :] = np.zeros((1, 768))\n",
    "# np.save('ViT_retrieval_matrix.npy', retrieval_matrix)\n",
    "# print(retrieval_matrix.shape)\n",
    "# retrieval_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41331c18-134a-47d1-a11b-646d35a51419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Euclid_dist(B1, B2):\n",
    "    # B1 = query_matrix\n",
    "    # B2 = retrieval_matrix\n",
    "    distances = np.zeros((B1.shape[0], B2.shape[0]))\n",
    "    for i in range(200):\n",
    "        distances[i, :] = np.sum((B1[i] - B2)**2, axis = 1)\n",
    "    distances = distances**0.5\n",
    "    return distances\n",
    "def get_topk(B1, B2, topk): #get topk idx\n",
    "    ind = np.argsort(calc_Euclid_dist(B1, B2))\n",
    "    ids = np.array(range(B2.shape[0]))\n",
    "    ids = ids[ind]\n",
    "    return ids[:, :topk]\n",
    "def get_L2(B1, B2, topk): # get topk labels\n",
    "    ids = list(get_topk(B1, B2, topk))\n",
    "    topk_labels = retrieval_labels[ids]\n",
    "    # L2 = [[img_vector_lst[j][0] for j in i] for i in ids] #[[arr[j] for j in i] for i in idx]\n",
    "    # print(topk_labels)\n",
    "    return topk_labels\n",
    "\n",
    "def calc_topk_mAP_2(B1, B2, L1, topk): \n",
    "    '''\n",
    "    B1: query matrix\n",
    "    B2: retrieval matrix\n",
    "    L1: labels of query images\n",
    "    topk: k\n",
    "    '''\n",
    "    topk_retrievals = get_L2(B1, B2, topk)\n",
    "    topk_mAP = 0\n",
    "    num_query = B1.shape[0]\n",
    "    # fig, axes = plt.subplots(num_query, topk+1, figsize=(12, 8))\n",
    "    for iter in tqdm(range(num_query)):\n",
    "        true_label = L1[iter].split('_')\n",
    "        true_idx = []\n",
    "        # axes[iter, 0].imshow(plt.imread('query_images/'+L1[iter]))\n",
    "        # axes[iter, 0].axis('off')\n",
    "        for i in range(topk):\n",
    "            # axes[iter, i+1].imshow(plt.imread('images/'+topk_retrievals[iter][i]))\n",
    "            # axes[iter, i+1].axis('off')\n",
    "            if topk_retrievals[iter][i].split('_')[0] == true_label[0]:\n",
    "                true_idx.append(i+1)\n",
    "        true_idx = np.array(true_idx)\n",
    "        # true_idx = (np.asarray(np.where(L2[ids][iter, :]==true_label)) + 1).ravel()\n",
    "        # print('true_idx', true_idx)\n",
    "        if true_idx.shape[0] == 0:\n",
    "            continue\n",
    "        count = np.linspace(1, true_idx.shape[0], true_idx.shape[0])\n",
    "        # print('count', count)\n",
    "        topk_mAP_ = np.mean(count/true_idx)\n",
    "        # print('topk_mAP_:', topk_mAP_)\n",
    "        # print('==========================================')\n",
    "        topk_mAP += topk_mAP_\n",
    "    # plt.tight_layout()  # Ensure subplots do not overlap\n",
    "    # plt.show()\n",
    "    topk_mAP /= num_query\n",
    "    # print('=====================================================================')\n",
    "    # print('topk_mAP', topk_mAP)\n",
    "    return topk_mAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "998e7921-e8e9-4f87-a51f-00306aaba4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 768), (200,), (10000, 768), (10000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_matrix = np.load('ViT_query_matrix.npy')\n",
    "query_labels = np.load('query_labels.npy')\n",
    "retrieval_matrix = np.load('ViT_retrieval_matrix.npy')\n",
    "retrieval_labels = np.load('retrieval_labels.npy')\n",
    "query_matrix.shape, query_labels.shape, retrieval_matrix.shape, retrieval_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32bdc7dc-bd91-4c09-bb19-e2b93d8540a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9991, 768), (9991,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_idx = [2749, 3952, 4893, 5296, 6288, 8028, 8463, 8735, 9697]\n",
    "retrieval_matrix =  np.delete(retrieval_matrix , error_idx, axis=0) \n",
    "retrieval_labels = np.delete(retrieval_labels , error_idx, axis=0) \n",
    "retrieval_matrix.shape, retrieval_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e13632bf-e2e3-4d53-8b34-4eaffbaad298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT mAP: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 200/200 [00:00<00:00, 126220.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@1: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 200/200 [00:00<00:00, 83427.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@5: 0.6746874999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 200/200 [00:00<00:00, 68990.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@10: 0.666942290249433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 200/200 [00:00<00:00, 55764.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@20: 0.6328467856252629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 200/200 [00:00<00:00, 21542.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@100: 0.5486334198563292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 200/200 [00:00<00:00, 2505.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@1000: 0.47086394329307507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [00:00<00:00, 252.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@9991: 0.37759100946225294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topk_lst = [1, 5, 10, 20, 100, 1000,retrieval_labels.shape[0]]\n",
    "print('ViT mAP: ')\n",
    "for i in topk_lst:\n",
    "    print(f'mAP@{i}:', calc_topk_mAP_2(query_matrix, retrieval_matrix, query_labels, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
